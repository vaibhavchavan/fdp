{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49812fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17464789/17464789 [==============================] - 51s 3us/step\n",
      "Epoch 1/5\n",
      "313/313 [==============================] - 8s 19ms/step - loss: 0.5569 - accuracy: 0.7071 - val_loss: 0.3912 - val_accuracy: 0.8226\n",
      "Epoch 2/5\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.3149 - accuracy: 0.8668 - val_loss: 0.3491 - val_accuracy: 0.8454\n",
      "Epoch 3/5\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.2271 - accuracy: 0.9123 - val_loss: 0.4009 - val_accuracy: 0.8400\n",
      "Epoch 4/5\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.1759 - accuracy: 0.9335 - val_loss: 0.3971 - val_accuracy: 0.8300\n",
      "Epoch 5/5\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.1507 - accuracy: 0.9423 - val_loss: 0.4684 - val_accuracy: 0.8268\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.4672 - accuracy: 0.8289\n",
      "Test accuracy: 0.8288800120353699\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
    "\n",
    "# Load the IMDB dataset\n",
    "max_features = 10000  # Number of unique words to consider\n",
    "maxlen = 100  # Cut sequences after this number of words\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=max_features)\n",
    "\n",
    "# Preprocess the data\n",
    "train_data = pad_sequences(train_data, maxlen=maxlen)\n",
    "test_data = pad_sequences(test_data, maxlen=maxlen)\n",
    "\n",
    "# Define the RNN model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_features, output_dim=32, input_length=maxlen))  # Word embeddings\n",
    "model.add(SimpleRNN(32, activation='relu'))  # RNN layer\n",
    "model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_data, train_labels,\n",
    "                    epochs=5,\n",
    "                    batch_size=64,\n",
    "                    validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_data, test_labels)\n",
    "print(f'Test accuracy: {test_acc}')\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ab532c35",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "    Data Preprocessing:\n",
    "        The IMDB dataset is loaded with a maximum of 10,000 unique words (max_features).\n",
    "        Sequences of words are padded to a fixed length (maxlen=100) using pad_sequences.\n",
    "\n",
    "    RNN Model:\n",
    "        An Embedding layer maps words into dense vectors of fixed size (output_dim=32).\n",
    "        A SimpleRNN layer processes the sequence, with 32 units and ReLU activation.\n",
    "        A Dense output layer with a sigmoid activation predicts the probability of the sentiment (positive/negative).\n",
    "\n",
    "    Model Compilation & Training:\n",
    "        The model uses the Adam optimizer, binary cross-entropy loss (appropriate for binary classification), and accuracy as the metric.\n",
    "        The model is trained for 5 epochs, and the validation set is 20% of the training data.\n",
    "\n",
    "    Evaluation:\n",
    "        The test set is used to evaluate the model's accuracy on unseen data.\n",
    "\n",
    "Output:\n",
    "\n",
    "The training process will display the accuracy and loss for both training and validation data during each epoch. At the end, the test accuracy will be printed.\n",
    "\n",
    "This is a simple RNN example. You can enhance it by using more advanced architectures like LSTMs or GRUs, which handle long-term dependencies better than SimpleRNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a8adf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
